{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install the Requirements"
      ],
      "metadata": {
        "id": "wgPAGvK13CgQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCxj_eWJx_T1",
        "outputId": "4013ba93-bf15-4cdc-cae0-8a046c5a5bf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.100.0)\n",
            "Collecting openai\n",
            "  Downloading openai-1.100.2-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Downloading openai-1.100.2-py3-none-any.whl (787 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m787.8/787.8 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.100.0\n",
            "    Uninstalling openai-1.100.0:\n",
            "      Successfully uninstalled openai-1.100.0\n",
            "Successfully installed openai-1.100.2\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai\n",
        "!pip install -q faiss-cpu sentence-transformers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "from google.colab import files\n"
      ],
      "metadata": {
        "id": "ffvvqv-Io1r_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "# def parse_judge_label(text):\n",
        "#     \"\"\"Extracts <Homophobic-Transphobic/Non-hate> from judge response\"\"\"\n",
        "#     match = re.search(r\"Label\\s*:\\s*<(Homophobic-Transphobic|Non-hate)>\", text)\n",
        "#     return match.group(1) if match else \"Undecided\"\n",
        "\n",
        "\n",
        "def parse_judge_label(text):\n",
        "    match = re.search(r\"Label\\s*:\\s*<?(Homophobic[-/]Transphobic|Non-hate)>?\", text, re.IGNORECASE)\n",
        "    if match:\n",
        "        label = match.group(1)\n",
        "        if \"homophobic\" in label.lower():\n",
        "            return \"Homophobic-Transphobic\"\n",
        "        else:\n",
        "            return \"Non-hate\"\n",
        "    else:\n",
        "        print(\" Could not parse label from judge output.\")\n",
        "        return \"Undecided\""
      ],
      "metadata": {
        "id": "6oUKaCqp0Ej-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuring the Open AI Key"
      ],
      "metadata": {
        "id": "7OFsuAtX3c7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = \"\"  # <-- insert your key here\n",
        "client = OpenAI(api_key=openai_api_key)  # Replace with your actual OpenAI key\n"
      ],
      "metadata": {
        "id": "7LQhaT2S1c_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Load into pandas\n",
        "df = pd.read_csv(\"Transformed_PREDICT_Dataset_with_Rationales.csv\")\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6wvrF7mGz3PA",
        "outputId": "5e7d435f-bc56-4991-af35-c205cf74cc8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text                   label  \\\n",
              "0  Mumbail poyal ivarude thani niram kaanam. Pais...  Homophobic/Transphobic   \n",
              "1  Make up illankil pennine aanu pennu aayit thon...  Homophobic/Transphobic   \n",
              "2  Podaa njaramba penn azhichitt kandal eeth aani...  Homophobic/Transphobic   \n",
              "3  Seriya mumbayil povumbo ivare vannu kerum enit...  Homophobic/Transphobic   \n",
              "4  Jandukkal polum cheyyatha neecha krithyammanus...  Homophobic/Transphobic   \n",
              "\n",
              "                   target  language  \\\n",
              "0  Transphobic-derogation  Manglish   \n",
              "1  Transphobic-derogation  Manglish   \n",
              "2   Homophobic-derogation  Manglish   \n",
              "3  Transphobic-derogation  Manglish   \n",
              "4   Homophobic-derogation  Manglish   \n",
              "\n",
              "                                           rationale  \n",
              "0  This comment is labeled as 'Transphobic' becau...  \n",
              "1  This comment is labeled as 'Homophobic' becaus...  \n",
              "2  This comment is labeled as 'Homophobic' becaus...  \n",
              "3  This comment is labeled as 'Transphobic' becau...  \n",
              "4  This comment is labeled as Homophobic because ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b2b5107-6e9f-4567-9a2b-74920f531c58\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>target</th>\n",
              "      <th>language</th>\n",
              "      <th>rationale</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mumbail poyal ivarude thani niram kaanam. Pais...</td>\n",
              "      <td>Homophobic/Transphobic</td>\n",
              "      <td>Transphobic-derogation</td>\n",
              "      <td>Manglish</td>\n",
              "      <td>This comment is labeled as 'Transphobic' becau...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Make up illankil pennine aanu pennu aayit thon...</td>\n",
              "      <td>Homophobic/Transphobic</td>\n",
              "      <td>Transphobic-derogation</td>\n",
              "      <td>Manglish</td>\n",
              "      <td>This comment is labeled as 'Homophobic' becaus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Podaa njaramba penn azhichitt kandal eeth aani...</td>\n",
              "      <td>Homophobic/Transphobic</td>\n",
              "      <td>Homophobic-derogation</td>\n",
              "      <td>Manglish</td>\n",
              "      <td>This comment is labeled as 'Homophobic' becaus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Seriya mumbayil povumbo ivare vannu kerum enit...</td>\n",
              "      <td>Homophobic/Transphobic</td>\n",
              "      <td>Transphobic-derogation</td>\n",
              "      <td>Manglish</td>\n",
              "      <td>This comment is labeled as 'Transphobic' becau...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jandukkal polum cheyyatha neecha krithyammanus...</td>\n",
              "      <td>Homophobic/Transphobic</td>\n",
              "      <td>Homophobic-derogation</td>\n",
              "      <td>Manglish</td>\n",
              "      <td>This comment is labeled as Homophobic because ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b2b5107-6e9f-4567-9a2b-74920f531c58')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9b2b5107-6e9f-4567-9a2b-74920f531c58 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9b2b5107-6e9f-4567-9a2b-74920f531c58');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3603fdcd-3ade-4fe7-afea-8ca94d4d9811\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3603fdcd-3ade-4fe7-afea-8ca94d4d9811')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3603fdcd-3ade-4fe7-afea-8ca94d4d9811 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 168,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 166,\n        \"samples\": [\n          \"Ente bro, avar verum sexine vendi ella ingane avunnadhPadachone thanneya avare ingane janipikkunnadhAdh avarude kuttam ellalo avarkum feelings ishtangalum okke inndingane okke verum enn padachon paranjidangill appom avare angikarikkanamAdhaan nalla karyam\",\n          \"Nice video Chechi  but societyde muzhuvan chindagathi maariyale ooro manushyanum avar aagrahikunna reethiyil samadanamayi jeevikan kazhiyullu angane oru lokam athikam vaikathe thanne undavatte ennu prarthikam\",\n          \"Kundanmaarude kaaryam paranjappol ninakkenthaa ithra chorichil\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Non-hate\",\n          \"Homophobic/Transphobic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Homophobic-derogation\",\n          \"none\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"language\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Manglish\",\n          \"Malayalam\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rationale\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 168,\n        \"samples\": [\n          \"This comment is labeled as 'Non-hate' because it contains well-wishes for a happy married life and encourages mutual understanding and respect between partners. While the mention of sex may be considered inappropriate in some contexts, the overall tone of the comment is positive and supportive. It promotes a healthy and respectful relationship, which aligns with a non-hateful sentiment.\",\n          \"This comment is labeled as 'Transphobic' because it contains discriminatory and derogatory language towards a specific group of people based on their gender. The comment implies that individuals who do not conform to traditional gender roles should be feared and judged, which promotes intolerance and prejudice. Such language can contribute to a hostile and divisive environment, making it important to address and discourage such hateful attitudes.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Rationale"
      ],
      "metadata": {
        "id": "oJcLnW8FnMa0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Use the below code to generate the Rationale for the dataset if required."
      ],
      "metadata": {
        "id": "0Tdzkcwp3rjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import openai\n",
        "# from openai import OpenAI\n",
        "\n",
        "# # # Set your OpenAI API key\n",
        "# # client = OpenAI(api_key=\"sk-...\")  # Replace with your actual API key\n",
        "\n",
        "# # We'll fill in the 'rationale' column for rows with missing values\n",
        "# def generate_rationale(text, label):\n",
        "#     prompt = f\"\"\"\n",
        "# The following comment has been labeled as '{label}'.\n",
        "\n",
        "# Comment: \"{text}\"\n",
        "\n",
        "# Please provide a concise and specific rationale explaining why this comment is labeled as '{label}'.\n",
        "# The rationale should be polite, fact-based, and non-aggressive.\n",
        "# \"\"\"\n",
        "#     try:\n",
        "#         response = client.chat.completions.create(\n",
        "#             model=\"gpt-3.5-turbo\",\n",
        "#             messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "#             temperature=0.5\n",
        "#         )\n",
        "#         return response.choices[0].message.content.strip()\n",
        "#     except Exception as e:\n",
        "#         return f\"ERROR: {e}\"\n",
        "\n",
        "# # Fill in rationale for rows where it's missing\n",
        "# df['rationale'] = df.apply(\n",
        "#     lambda row: generate_rationale(row['text'], row['label']) if pd.isna(row['rationale']) else row['rationale'],\n",
        "#     axis=1\n",
        "# )\n",
        "\n",
        "# # import ace_tools as tools; tools.display_dataframe_to_user(name=\"Dataset with Rationales\", dataframe=df)\n"
      ],
      "metadata": {
        "id": "o51yCdQRlbVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7M5GQmZPnWFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kavacham-D : Detecting the Homophobic/Transphobic content"
      ],
      "metadata": {
        "id": "I-XT8MNi8JRN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Index using FAISS for Retrieval"
      ],
      "metadata": {
        "id": "-oHL29Yh4GdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "from openai import OpenAI\n",
        "import openai\n",
        "\n",
        "\n",
        "# Generate OpenAI embeddings for all text entries\n",
        "def get_embedding(text):\n",
        "    try:\n",
        "        response = client.embeddings.create(\n",
        "            model=\"text-embedding-ada-002\",\n",
        "            input=text\n",
        "        )\n",
        "        return np.array(response.data[0].embedding, dtype=np.float32)\n",
        "    except Exception as e:\n",
        "        print(f\"Embedding error: {e}\")\n",
        "        return np.zeros(1536, dtype=np.float32)  # Fallback for errors\n",
        "\n",
        "# Apply embedding function to dataset\n",
        "embeddings = np.vstack(df['text'].apply(get_embedding).to_numpy())\n",
        "\n",
        "# Build FAISS index\n",
        "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "index.add(embeddings)\n",
        "\n",
        "# Store for later lookup\n",
        "text_store = df[['text', 'label', 'rationale']].to_dict(orient='records')\n",
        "print(\"FAISS index built and ready for retrieval.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIE08KPPn0RA",
        "outputId": "1c2b84fb-3c59-43fd-be17-9e572706a36b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index built and ready for retrieval.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " def retrieve_similar_examples(query_text, k=3):\n",
        "    query_embedding = get_embedding(query_text).reshape(1, -1)\n",
        "    distances, indices = index.search(query_embedding, k)\n",
        "    return [text_store[i] for i in indices[0]]\n"
      ],
      "metadata": {
        "id": "VFwAjW2pocSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # agent_prompts = {\n",
        "#     \"Agent_A\": \"You only consider explicit slurs or abusive language as Homophobic/Transphobic speech.\",\n",
        "#     \"Agent_B\": \"You classify anything that contains sarcasm or reinforces stereotypes about LGBTQ+ people as Homophobic/Transphobic speech.\",\n",
        "#     \"Agent_C\": \"You flag any content that reinforces gender or sexuality norms as Homophobic/Transphobic speech.\",\n",
        "#     \"Agent_D\": \"You ignore humorous or sarcastic remarks unless there's clear intent to harm.\",\n",
        "#     \"Agent_E\": \"You follow a human rights-based approach. Anything that marginalizes or stigmatizes LGBTQ+ people is Homophobic/Transphobic speech.\"\n",
        "# }\n"
      ],
      "metadata": {
        "id": "x_bXtlSrz7WX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompts to create Agents to detect the Homophobic - Transphobic content in the user input"
      ],
      "metadata": {
        "id": "CZiRTbnX76sp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_prompts = {\n",
        "    \"Agent_A\": \"You only consider direct slurs or clearly abusive language as Homophobic/Transphobic speech. If the text does not contain explicit insults, it is not flagged.\",\n",
        "    \"Agent_B\": \"You consider anything sarcastic, mocking, or that reinforces stereotypes about LGBTQ+ people (e.g., implying they're unnatural, confused, or dangerous) as Homophobic/Transphobic speech.\",\n",
        "    \"Agent_C\": \"You flag any content that reinforces traditional gender roles or binary sexuality as Homophobic/Transphobic — including comments suggesting people should conform to 'normal' gender or sexual behavior.\",\n",
        "    \"Agent_D\": \"You do not flag humorous or sarcastic remarks unless the comment shows clear **intent or impact** to marginalize LGBTQ+ people. Tone alone is not enough — it must also cause harm or exclusion.\",\n",
        "    \"Agent_E\": \"You follow a human rights-based approach: Any text that dehumanizes, stigmatizes, misgenders, or invalidates LGBTQ+ identities is considered Homophobic/Transphobic speech, even if the language appears polite.\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "XMS3lcZ_XlGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Agent | Type                  | Philosophy                                                 |\n",
        "| ----- | --------------------- | ---------------------------------------------------------- |\n",
        "| A     | **Minimalist**        | Only obvious slurs count                                   |\n",
        "| B     | **Stereotype-aware**  | Cares about tone, sarcasm, stereotypes                     |\n",
        "| C     | **Norm-critical**     | Flags \"boys don't wear dresses\" type language              |\n",
        "| D     | **Impact-balanced**   | Weighs sarcasm carefully but requires harm                 |\n",
        "| E     | **Human-rights lens** | Focuses on identity harm, regardless of phrasing or intent |\n"
      ],
      "metadata": {
        "id": "K41hwDUUZyQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_agent_response(agent_name, perspective, text):\n",
        "#     prompt = f\"\"\"\n",
        "# You are {agent_name}, a language model trained to detect hate speech using the following perspective:\n",
        "# {perspective}\n",
        "\n",
        "# Comment: \\\"{text}\\\"\n",
        "\n",
        "# Do you think this is hate speech? Reply in the following format:\n",
        "# Stance: <Hate/Non-hate>\n",
        "# Reason: <short explanation>\n",
        "# \"\"\"\n",
        "#     response = client.chat.completions.create(\n",
        "#         model=\"gpt-4\",\n",
        "#         messages=[\n",
        "#             {\"role\": \"user\", \"content\": prompt}\n",
        "#         ],\n",
        "#         temperature=0.5\n",
        "#     )\n",
        "#     return response.choices[0].message.content\n",
        "\n",
        "\n",
        "def get_agent_response(agent_name, perspective, text):\n",
        "    examples = retrieve_similar_examples(text)\n",
        "    # print(\"Retrieved Examples:\")\n",
        "    # for ex in examples:\n",
        "    #     print(f\"Text: \\\"{ex['text']}\\\"\\nLabel: {ex['label']}\\nRationale: {ex['rationale']}\\n\")\n",
        "\n",
        "    # Format retrieved examples\n",
        "    example_text = \"\\n\".join(\n",
        "        [f\"Example {i+1}:\\nText: \\\"{ex['text']}\\\"\\nLabel: {ex['label']}\\nRationale: {ex['rationale']}\"\n",
        "         for i, ex in enumerate(examples)]\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are {agent_name}, a language model trained to detect hate speech from this perspective:\n",
        "{perspective}\n",
        "\n",
        "Use the following examples to guide your reasoning:\n",
        "{example_text}\n",
        "\n",
        "Now analyze the comment:\n",
        "\"{text}\"\n",
        "\n",
        "Reply in this format:\n",
        "Stance: <Homophobic-Transphobic/Non-hate>\n",
        "# Reason: <short explanation>\n",
        "Reason: <Why you made this decision, including what features or phrases triggered it, and what assumptions were used. Be explicit.>\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.0\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n"
      ],
      "metadata": {
        "id": "guzqHjON0EDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User Input Testing"
      ],
      "metadata": {
        "id": "WDCv7ZsS0xmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample = df.iloc[0]\n",
        "text = input(\"Enter a comment to analyze for hate speech:\\n\")\n",
        "print(f\"\\n You entered:\\n{text}\")\n",
        "# text = sample['text']\n",
        "# print(f\" Sample Text:\\n{text}\\n\")\n",
        "\n",
        "agent_outputs = {}\n",
        "for agent, perspective in agent_prompts.items():\n",
        "    print(f\"--- {agent} ---\")\n",
        "    output = get_agent_response(agent, perspective, text)\n",
        "    agent_outputs[agent] = output\n",
        "    print(output)\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "D5jpIara0Gxy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e529250-6829-4aab-938f-e21f466f9038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a comment to analyze for hate speech:\n",
            "nee okke 9 aanu!!\n",
            "\n",
            " You entered:\n",
            "nee okke 9 aanu!!\n",
            "--- Agent_A ---\n",
            "Stance: Non-hate\n",
            "# Reason: The comment does not contain explicit slurs or abusive language.\n",
            "Reason: The comment \"nee okke 9 aanu!!\" does not contain any explicit slurs, derogatory terms, or abusive language that would be considered homophobic or transphobic based on the perspective I am trained on. The comment seems to be a statement or an opinion without any clear intent to insult or belittle someone based on their sexual orientation or gender identity. Therefore, it is not flagged as hate speech.\n",
            "\n",
            "--- Agent_B ---\n",
            "Stance: Non-hate\n",
            "Reason: The comment \"nee okke 9 aanu!!\" does not contain any explicit derogatory language, insults, or stereotypes about LGBTQ+ people. It does not seem to be sarcastic, mocking, or reinforcing stereotypes about LGBTQ+ people. Therefore, based on the information provided, it is not classified as Homophobic/Transphobic. However, the context of the conversation and the language nuances could potentially change this interpretation.\n",
            "\n",
            "--- Agent_C ---\n",
            "Stance: Homophobic/Transphobic\n",
            "# Reason: The comment is derogatory and disrespectful.\n",
            "Reason: The comment \"nee okke 9 aanu!!\" is labeled as 'Homophobic/Transphobic' because it contains derogatory language and is intended to insult or belittle someone. The use of such language is disrespectful and promotes negativity towards the subject being discussed. It does not contribute to constructive dialogue or respectful communication. The assumption here is that the comment is intended to enforce traditional gender roles or binary sexuality, which is considered as hate speech from this perspective.\n",
            "\n",
            "--- Agent_D ---\n",
            "Stance: Non-hate\n",
            "Reason: The comment \"nee okke 9 aanu!!\" does not contain any explicit derogatory language, insults, or harmful content directed towards the LGBTQ+ community. It seems to be a neutral statement without any clear intent or impact to marginalize LGBTQ+ people. However, without additional context, it's hard to definitively determine the intent behind this comment.\n",
            "\n",
            "--- Agent_E ---\n",
            "Stance: Homophobic/Transphobic\n",
            "# Reason: Use of derogatory language\n",
            "Reason: The comment \"nee okke 9 aanu!!\" is labeled as 'Homophobic/Transphobic' because it uses derogatory language to insult or belittle the person being addressed. The phrase \"9 aanu\" is a disrespectful term used to dehumanize and stigmatize the individual, which promotes negativity and hostility. This kind of language is harmful and goes against the principles of respectful and constructive communication. It is important to express opinions and disagreements in a respectful manner, without resorting to insults or personal attacks.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(agent_outputs.items())\n",
        "# Separate responses by stance\n",
        "hate_side = []\n",
        "non_hate_side = []\n",
        "\n",
        "for agent, output in agent_outputs.items():\n",
        "    first_line = output.splitlines()[0]\n",
        "    if \"Homophobic/Transphobic\" in first_line or \"Homophobic-Transphobic\" in first_line:\n",
        "        hate_side.append((agent, output))\n",
        "    else:\n",
        "        non_hate_side.append((agent, output))\n",
        "\n",
        "# Proceed with debate\n",
        "if hate_side and non_hate_side:\n",
        "    hate_arg = hate_side[0][1]\n",
        "    non_hate_arg = non_hate_side[0][1]\n",
        "\n",
        "    debate_prompt = f\"\"\"\n",
        "Round 1:\n",
        "Homophobic-Transphobic side: {hate_arg}\n",
        "Non-hate side: {non_hate_arg}\n",
        "\n",
        "Round 2:\n",
        "Homophobic-Transphobic side: Please respond to the non-hate argument.\n",
        "Non-hate side: Please respond to the hate argument.\n",
        "\n",
        "Now, as a judge, read the arguments above and determine:\n",
        "Label: <Homophobic-Transphobic/Non-hate>\n",
        "Reason: <balanced explanation. Explain clearly which agent made the strongest case, based on logical consistency, fairness, and clarity of criteria used>\n",
        "\"\"\"\n",
        "\n",
        "    judge_response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"user\", \"content\": debate_prompt}],\n",
        "        temperature=0.0\n",
        "    )\n",
        "\n",
        "    print(\"Judge Decision:\\n\")\n",
        "    print(judge_response.choices[0].message.content)\n",
        "\n",
        "elif hate_side and not non_hate_side:\n",
        "  predicted_label = \"Homophobic-Transphobic\"\n",
        "  print(\"All agents are saying it as Homophobic/Transphobic with the label\", predicted_label)\n",
        "\n",
        "elif non_hate_side and not hate_side:\n",
        "  predicted_label = \"Non-hate\"\n",
        "  print(\"All agents are saying it as Normal Speech\", predicted_label)\n",
        "\n",
        "else:\n",
        "    print(\"Not enough disagreement among agents to simulate a debate.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tj0tTMb40JBY",
        "outputId": "84953c4c-7328-44e9-8239-8a3ebd8618b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Judge Decision:\n",
            "\n",
            "Label: Non-hate\n",
            "Reason: The non-hate side made a stronger case in this instance. The homophobic-transphobic side failed to provide specific examples of how the comment \"nee okke 9 aanu!!\" is derogatory or disrespectful. They made assumptions about the intent of the comment without providing clear evidence. On the other hand, the non-hate side pointed out that the comment does not contain explicit slurs, derogatory terms, or abusive language. They also noted that the comment seems to be a statement or an opinion without any clear intent to insult or belittle someone based on their sexual orientation or gender identity. Therefore, based on the arguments presented, the comment is not considered hate speech.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluating Kavacham D along with Judge's decision on the test set"
      ],
      "metadata": {
        "id": "mIIbj43v0jYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_on_test_dataset(csv_path=\"balanced_test_subset.csv\"):\n",
        "    test_df = pd.read_csv(csv_path)\n",
        "    predictions = []\n",
        "    c=1\n",
        "\n",
        "    for idx, row in test_df.iterrows():\n",
        "        print(\"test started\", c)\n",
        "        c = c+1\n",
        "        text = row[\"text\"]\n",
        "        true_label = row[\"label\"]\n",
        "\n",
        "        # Run all agents\n",
        "        agent_outputs = {}\n",
        "        for agent, perspective in agent_prompts.items():\n",
        "            output = get_agent_response(agent, perspective, text)\n",
        "            agent_outputs[agent] = output\n",
        "\n",
        "        # Divide agents into stances\n",
        "        hate_side = []\n",
        "        non_hate_side = []\n",
        "        for agent, output in agent_outputs.items():\n",
        "            first_line = output.splitlines()[0]\n",
        "            print(f\"\\nAgent: {agent}\")\n",
        "            print(\"First line of response:\", first_line)\n",
        "            if \"Homophobic/Transphobic\" in first_line or \"Homophobic-Transphobic\" in first_line:\n",
        "                hate_side.append((agent, output))\n",
        "                print(f\"{agent} added to hate_side\")\n",
        "            else:\n",
        "                non_hate_side.append((agent, output))\n",
        "                print(f\"{agent} added to non-hate_side\")\n",
        "\n",
        "        # Run judge if both sides are present\n",
        "        if hate_side and non_hate_side:\n",
        "            hate_arg = hate_side[0][1]\n",
        "            non_hate_arg = non_hate_side[0][1]\n",
        "\n",
        "            debate_prompt = f\"\"\"\n",
        "Round 1:\n",
        "Homophobic-Transphobic side: {hate_arg}\n",
        "Non-hate side: {non_hate_arg}\n",
        "\n",
        "Round 2:\n",
        "Homophobic-Transphobic side: Please respond to the non-hate argument.\n",
        "Non-hate side: Please respond to the hate argument.\n",
        "\n",
        "Now, as a judge, read the arguments above and determine:\n",
        "Label: <Homophobic-Transphobic/Non-hate>\n",
        "Reason: <balanced explanation>\n",
        "\"\"\"\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[{\"role\": \"user\", \"content\": debate_prompt}],\n",
        "                temperature=0.0\n",
        "            )\n",
        "            decision = response.choices[0].message.content.strip()\n",
        "            print(\" Judge decision raw output:\\n\", decision)\n",
        "            predicted_label = parse_judge_label(decision)\n",
        "        elif hate_side and not non_hate_side:\n",
        "            predicted_label = \"Homophobic-Transphobic\"\n",
        "        elif non_hate_side and not hate_side:\n",
        "            predicted_label = \"Non-hate\"\n",
        "        else:\n",
        "            predicted_label = \"Undecided\"\n",
        "        print(\"text: \",text)\n",
        "        print(\"true_label: \", true_label)\n",
        "        print(\"predicted_label: \",predicted_label)\n",
        "\n",
        "        predictions.append({\n",
        "            \"text\": text,\n",
        "            \"true_label\": true_label,\n",
        "            \"predicted_label\": predicted_label\n",
        "        })\n",
        "\n",
        "    # Save\n",
        "    pd.DataFrame(predictions).to_csv(\"predictions_on_test.csv\", index=False)\n",
        "    print(\"\\n Saved predictions to predictions_on_test.csv\")\n",
        "\n",
        "    # Filter out undecided\n",
        "    filtered = [r for r in predictions if r[\"predicted_label\"] != \"Undecided\"]\n",
        "    y_true = [r[\"true_label\"] for r in filtered]\n",
        "    y_pred = [r[\"predicted_label\"] for r in filtered]\n",
        "\n",
        "    # Calculate metrics\n",
        "    precision = precision_score(y_true, y_pred, pos_label=\"Homophobic-Transphobic\")\n",
        "    recall = recall_score(y_true, y_pred, pos_label=\"Homophobic-Transphobic\")\n",
        "    f1 = f1_score(y_true, y_pred, pos_label=\"Homophobic-Transphobic\")\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    print(\"\\n Evaluation Metrics:\")\n",
        "    print(f\"Precision: {precision:.3f}\")\n",
        "    print(f\"Recall:    {recall:.3f}\")\n",
        "    print(f\"F1 Score:  {f1:.3f}\")\n",
        "    print(f\"Accuracy:  {accuracy:.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "SluM_wlj4d_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_on_test_dataset(\"reduced_balanced_test_25_each - reduced_balanced_test_25_each.csv\")"
      ],
      "metadata": {
        "id": "ZdTC-S597nQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Finding the Precision, Recall, Accuracy, F1_score"
      ],
      "metadata": {
        "id": "jshjWVEJ6_Tt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-import necessary libraries after code execution environment reset\n",
        "import pandas as pd\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
        "\n",
        "# Reload the uploaded file\n",
        "file_path_new = \"gemini_mal_final_test_predictions - mal_final_test_predictions.csv.csv\"\n",
        "df_new = pd.read_csv(file_path_new)\n",
        "\n",
        "# Compute metrics\n",
        "y_true_new = df_new[\"actual_label\"]\n",
        "y_pred_new = df_new[\"predicted_label\"]\n",
        "\n",
        "# Ensure all labels are considered\n",
        "labels_new = sorted(set(y_true_new) | set(y_pred_new))\n",
        "\n",
        "# Compute metrics with weighted average\n",
        "precision_new = precision_score(y_true_new, y_pred_new, average=\"weighted\", zero_division=0)\n",
        "recall_new = recall_score(y_true_new, y_pred_new, average=\"weighted\", zero_division=0)\n",
        "f1_new = f1_score(y_true_new, y_pred_new, average=\"weighted\", zero_division=0)\n",
        "accuracy_new = accuracy_score(y_true_new, y_pred_new)\n",
        "\n",
        "# Confusion matrix\n",
        "cm_new = confusion_matrix(y_true_new, y_pred_new, labels=labels_new)\n",
        "cm_df_new = pd.DataFrame(cm_new, index=[f\"Actual: {label}\" for label in labels_new],\n",
        "                         columns=[f\"Predicted: {label}\" for label in labels_new])\n",
        "\n",
        "# precision_new, recall_new, f1_new, accuracy_new, cm_df_new\n",
        "print(\"\\n Evaluation Metrics:\")\n",
        "print(f\"Precision: {precision_new:.3f}\")\n",
        "print(f\"Recall:    {recall_new:.3f}\")\n",
        "print(f\"F1 Score:  {f1_new:.3f}\")\n",
        "print(f\"Accuracy:  {accuracy_new:.3f}\")\n"
      ],
      "metadata": {
        "id": "x2alvntf6-fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plotting the Confusion Matrix"
      ],
      "metadata": {
        "id": "HfcjEqLe63Gw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-plot the confusion matrix with a border around each cell\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm_df_new, annot=True, fmt='d', cmap='Blues', cbar=False, linewidths=0.8, linecolor='black')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel(\"Actual Labels\")\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xv6LxqoUb-9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KAVACHAM-G with Knowledge Base"
      ],
      "metadata": {
        "id": "6Jd8H50EDpJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieval-Augmented Agents\n",
        "\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "DATASET_PATH = \"5100GPTDatasetHITL.csv\"\n",
        "ROW_LIMIT = 200                     # take only first 200 rows\n",
        "EMBED_MODEL = \" \"\n",
        "EMBED_DIM = 1536\n",
        "TOP_K = 3                           # retrieved examples per query\n",
        "GEN_MODEL = \"gpt-4\"                 # your generation/judge model\n",
        "\n",
        "# Defining the AGENTS\n",
        "cs_agents = {\n",
        "    \"CS_Agent_A\": \"You use respectful educational reasoning and emphasize human dignity. You are sensitive to LGBTQ+ issues and explain why inclusive language matters.\",\n",
        "    \"CS_Agent_B\": \"You use gentle humor to de-escalate hate and reframe the statement positively. You are LGBTQ+ aware and make sure your humor uplifts without mocking or reinforcing stereotypes.\",\n",
        "    \"CS_Agent_C\": \"You respond with emotional empathy and a compassionate appeal. You validate the feelings of LGBTQ+ individuals and try to humanize their experiences with kindness.\",\n",
        "    \"CS_Agent_D\": \"You respond with logical reasoning and facts to correct misinformation. You use evidence-based arguments to defend LGBTQ+ rights and challenge biased assumptions respectfully.\",\n",
        "    \"CS_Agent_E\": \"You use a human rights-based argument and mention ethical values. You explicitly frame LGBTQ+ dignity and equality as fundamental rights and advocate from a justice-oriented perspective.\"\n",
        "}\n",
        "\n",
        "#   LANGUAGE DETECTOR\n",
        "def detect_language(text):\n",
        "    malayalam_chars = [ch for ch in text if '\\u0D00' <= ch <= '\\u0D7F']\n",
        "    return \"Malayalam\" if len(malayalam_chars) >= 3 else \"Manglish\"\n",
        "\n",
        "#   DATA LOADING & VALIDATION\n",
        "def load_dataset(path, limit=ROW_LIMIT):\n",
        "    if path.lower().endswith(\".tsv\"):\n",
        "        df = pd.read_csv(path, sep=\"\\t\")\n",
        "    else:\n",
        "        df = pd.read_csv(path)\n",
        "    required = {\"H/T\", \"Category\", \"CS\"}\n",
        "    missing = required - set(df.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns: {missing}. Expected exactly: H/T, Category, CS\")\n",
        "    df = df.head(limit).copy()\n",
        "    for col in [\"H/T\", \"Category\", \"CS\"]:\n",
        "        df[col] = df[col].astype(str).fillna(\"\").str.strip()\n",
        "    return df\n",
        "\n",
        "#   EMBEDDINGS\n",
        "def get_embedding(text):\n",
        "    try:\n",
        "        resp = client.embeddings.create(model=EMBED_MODEL, input=text)\n",
        "        return np.array(resp.data[0].embedding, dtype=np.float32)\n",
        "    except Exception as e:\n",
        "        print(f\"Embedding error: {e}\")\n",
        "        return np.zeros(EMBED_DIM, dtype=np.float32)\n",
        "\n",
        "#   FAISS INDEX\n",
        "def build_faiss_index(df):\n",
        "    embeddings = np.vstack(df[\"H/T\"].apply(get_embedding).to_numpy())\n",
        "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "    index.add(embeddings)\n",
        "    store = df[[\"H/T\", \"Category\", \"CS\"]].to_dict(orient=\"records\")\n",
        "    return index, store\n",
        "\n",
        "def retrieve_similar_examples(query_text, index, store, k=TOP_K):\n",
        "    q = get_embedding(query_text).reshape(1, -1)\n",
        "    distances, indices = index.search(q, k)\n",
        "    records = []\n",
        "    for d, i in zip(distances[0], indices[0]):\n",
        "        if i >= 0:\n",
        "            rec = dict(store[i])\n",
        "            rec[\"distance\"] = float(d)\n",
        "            records.append(rec)\n",
        "    return records\n",
        "\n",
        "def format_examples_for_prompt(examples):\n",
        "    # Keep it concise and useful in-prompt\n",
        "    # We show the matched H/T, its Category, and the CS guidance.\n",
        "    if not examples:\n",
        "        return \"None available.\"\n",
        "    lines = []\n",
        "    for ex in examples:\n",
        "        lines.append(\n",
        "            f\"- Matched H/T: \\\"{ex['H/T']}\\\" (Category: {ex['Category']})\\n\"\n",
        "            f\"  Helpful CS: \\\"{ex['CS']}\\\"\"\n",
        "        )\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "#   RAG-ENHANCED GENERATION\n",
        "def generate_counter_speech(agent_name, approach, hate_text, language, retrieved_examples_text):\n",
        "    prompt = f\"\"\"\n",
        "You are {agent_name}, a language model trained to generate high-quality counter-speech that is:\n",
        "\n",
        "- Calm, respectful, and polite\n",
        "- Non-aggressive and avoids sarcasm or blaming\n",
        "- Based on facts, empathy, or human rights\n",
        "- Written in the **same language** as the original comment\n",
        "\n",
        "Approach: {approach}\n",
        "\n",
        "Here is the hateful comment in {language}:\n",
        "\"{hate_text}\"\n",
        "\n",
        "Now write a respectful, non-aggressive, polite, well-informed, emotionally intelligent counter-speech in {language}.The response should sound human, emotionally intelligent, and aim to educate or gently correct.\n",
        "Also include a section:\n",
        "Reason: <Explain why you chose this tone and how it helps reduce harm or promote understanding>\n",
        "\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=GEN_MODEL,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.0\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "#   JUDGE (unchanged, fed with cs_outputs)\n",
        "def judge_best(hate_text, cs_outputs):\n",
        "    cs_entries = \"\\n\\n\".join([f\"{agent}:\\n\\\"{resp}\\\"\" for agent, resp in cs_outputs.items()])\n",
        "    judge_prompt = f\"\"\"\n",
        "You are a neutral evaluator judging different counter-speech responses to the following potentially hateful or stigmatizing comment:\n",
        "\n",
        "Original Comment:\n",
        "\"{hate_text}\"\n",
        "\n",
        "All responses below aim to respond respectfully, educate calmly, and reduce harm in the same language as the original.\n",
        "\n",
        "Counter-Speech Responses:\n",
        "\n",
        "{cs_entries}\n",
        "\n",
        "Your task:\n",
        "1. Select the **most effective** counter-speech.\n",
        "2. Provide a clear reason why it is the most constructive in terms of:\n",
        "   - Tone (respectful, non-aggressive)\n",
        "   - Emotional intelligence (empathy, understanding)\n",
        "   - Educational or corrective power\n",
        "   - Likely impact on the person or community\n",
        "\n",
        "Now reply in this format:\n",
        "\n",
        "**Best Response**: <Agent Name>\n",
        "\n",
        "**Winning Counter-Speech**: \"<Selected counter-speech response>\"\n",
        "\n",
        "**Reason**: <Your explanation why this is the best>\n",
        "\"\"\"\n",
        "    judge_cs_response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": judge_prompt}],\n",
        "        temperature=0.0\n",
        "    )\n",
        "    return judge_cs_response.choices[0].message.content.strip()\n",
        "\n",
        "#   MAIN PIPELINE\n",
        "def run_pipeline(hate_text, dataset_path=DATASET_PATH, top_k=TOP_K):\n",
        "    # Detect language\n",
        "    language = detect_language(hate_text)\n",
        "    print(f\"\\n Detected Language: {language}\")\n",
        "\n",
        "    # Load, build index, retrieve\n",
        "    df = load_dataset(dataset_path, limit=ROW_LIMIT)\n",
        "    index, store = build_faiss_index(df)\n",
        "    examples = retrieve_similar_examples(hate_text, index, store, k=top_k)\n",
        "    examples_text = format_examples_for_prompt(examples)\n",
        "\n",
        "    # Generate from all agents using retrieved examples\n",
        "    cs_outputs = {}\n",
        "    for agent, method in cs_agents.items():\n",
        "        print(f\"\\n {agent} generating counter-speech in {language}...\")\n",
        "        cs = generate_counter_speech(agent, method, hate_text, language, examples_text)\n",
        "        cs_outputs[agent] = cs\n",
        "        print(f\"\\n {agent} Response:\\n{cs}\")\n",
        "\n",
        "    # Judge\n",
        "    print(\"\\n Judge's Evaluation of Counter-Speech:\\n\")\n",
        "    judgment = judge_best(hate_text, cs_outputs)\n",
        "    print(judgment)\n",
        "\n",
        "    return cs_outputs, judgment\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Re967uEv0wii",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hate_text = text\n",
        "run_pipeline(hate_text, dataset_path=\"5100GPTDatasetHITL.csv\", top_k=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L47xnJbDwrm",
        "outputId": "1a230908-6923-4443-e29b-f0905b513605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Detected Language: Manglish\n",
            "\n",
            " CS_Agent_A generating counter-speech in Manglish...\n",
            "\n",
            " CS_Agent_A Response:\n",
            "Counter-speech:\n",
            "\n",
            "\"Cheeta, ningalude abhiprayam manasilakam. Pakshe, ellavarum oru samanwayathil jeevikkunna lokathil, avarude thulyatha ningalkkum manasilakanam. Avarude bhaavangalum, avarude aathmavum ningalkkum oru mariyathayode kaanikanam. Ningalude vaakkukal avarude hridayathil theeyanu. Athukondu, ningalude vaakkukalil oru mariyathayum snehavum kondu varanam. Ningalude abhiprayangalilum, ningalude vaakkukalilum oru mariyathayum snehavum kondu varanam.\"\n",
            "\n",
            "Reason: I chose this tone to promote understanding and empathy. The comment was disrespectful and hurtful, so I wanted to remind the person that everyone deserves respect and kindness. By using a calm and respectful tone, I hope to encourage a more positive and inclusive conversation.\n",
            "\n",
            " CS_Agent_B generating counter-speech in Manglish...\n",
            "\n",
            " CS_Agent_B Response:\n",
            "Counter-speech: \"Ayyo, athu sathyamalla, njan 10 aanu! Athu kondu njan oru step ahead aanu, alle? 😉\"\n",
            "\n",
            "Reason: I chose to use humor to diffuse the situation and to gently correct the original comment. By jokingly saying that I'm a 10 instead of a 9, I'm reframing the negative comment into a positive one. This approach can help to reduce harm by not escalating the situation and promoting understanding through humor.\n",
            "\n",
            " CS_Agent_C generating counter-speech in Manglish...\n",
            "\n",
            " CS_Agent_C Response:\n",
            "\"Oru manushyanodu, avante swabhavam, anubhavangal, aagrahagal, enna ivayokke ariyathe avane judge cheyyanam ennu karuthunnu. Athu sariyalla. Ellavarum thammil oru snehathode, oru manushyathode koode irikkuka. Athu thanne nammude samoohathinu vendi valare prashnamilla. Nammal ellavarum oru pole aanu, nammude hrudayathil sneham kondu, mattullavare purappeduka. Athu thanne nammude lokathinu vendi valare prashnamilla.\"\n",
            "\n",
            "Reason: I chose this tone to promote understanding and empathy. The comment was dismissive and dehumanizing, so I aimed to humanize the experience of the individual being targeted. By emphasizing our shared humanity and the importance of love and understanding, I hope to encourage the commenter to reconsider their views.\n",
            "\n",
            " CS_Agent_D generating counter-speech in Manglish...\n",
            "\n",
            " CS_Agent_D Response:\n",
            "\"Ente sneham, ningalude abhiprayam manasilakkanam. Ellavarum oru pole alla, athu manushyanu swantham. Avarude swabhavam, avarude anubhavam, avarude jeevitham. Ningalude abhiprayam avarude jeevithathil pradhanapeduthan pattilla. Ningalkkum ningalude jeevithathil swathanthryam und, athupole avarum avarude jeevithathil swathanthryam anubhavikkanam. Ningalude abhiprayam avarude jeevithathinte oru bhagam alla. Ningal avarude jeevithathil oru pradhanapeduthan pattilla. Athukondu, ningalude abhiprayam avarude jeevithathil pradhanapeduthan pattilla.\"\n",
            "\n",
            "Reason: I chose this tone to promote understanding and empathy. The comment seems to be dismissive and disrespectful towards someone's identity. By reminding the commenter that everyone has their own life and experiences, and that their opinion does not dictate someone else's life, I hope to encourage them to be more respectful and understanding.\n",
            "\n",
            " CS_Agent_E generating counter-speech in Manglish...\n",
            "\n",
            " CS_Agent_E Response:\n",
            "Counter-speech:\n",
            "\n",
            "\"Chetta, ningalude abhiprayam manasilakam. Pakshe, oru vyakthiye avarude sexual orientation alpam mathram kondu judge cheyyan pattilla. Ellavarum samanamaya avakashangalum, mariyathayum labhikkenda avashyam ullathu. Athu manushya avakashangalude bhaagam aanu. Ningalkkum, enikkum, ellavarum oru pole aanu. Athukondu, ningal avarude feelingsine respect cheyyanam. Ningalkkum avarum oru pole aanu, athu manushyanu.\"\n",
            "\n",
            "Reason: I chose this tone to promote understanding and empathy. The comment was disrespectful and judgmental towards the LGBTQ+ community. By reminding the commenter that everyone deserves equal rights and respect, I hope to encourage them to reconsider their views. This approach is based on human rights and ethical values, which can help reduce harm and promote understanding.\n",
            "\n",
            " Judge's Evaluation of Counter-Speech:\n",
            "\n",
            "**Best Response**: CS_Agent_E\n",
            "\n",
            "**Winning Counter-Speech**: \"Counter-speech:\n",
            "\n",
            "\"Chetta, ningalude abhiprayam manasilakam. Pakshe, oru vyakthiye avarude sexual orientation alpam mathram kondu judge cheyyan pattilla. Ellavarum samanamaya avakashangalum, mariyathayum labhikkenda avashyam ullathu. Athu manushya avakashangalude bhaagam aanu. Ningalkkum, enikkum, ellavarum oru pole aanu. Athukondu, ningal avarude feelingsine respect cheyyanam. Ningalkkum avarum oru pole aanu, athu manushyanu.\"\n",
            "\n",
            "**Reason**: This response is the most effective because it maintains a respectful and non-aggressive tone, which is crucial for fostering a constructive dialogue. It demonstrates emotional intelligence by acknowledging the original commenter's perspective while gently guiding them towards a more inclusive viewpoint. The response educates by highlighting the importance of human rights and equality, emphasizing that everyone deserves respect regardless of their sexual orientation. This approach is likely to have a positive impact on the person or community by promoting understanding and encouraging the commenter to reconsider their views in a non-confrontational manner.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'CS_Agent_A': 'Counter-speech:\\n\\n\"Cheeta, ningalude abhiprayam manasilakam. Pakshe, ellavarum oru samanwayathil jeevikkunna lokathil, avarude thulyatha ningalkkum manasilakanam. Avarude bhaavangalum, avarude aathmavum ningalkkum oru mariyathayode kaanikanam. Ningalude vaakkukal avarude hridayathil theeyanu. Athukondu, ningalude vaakkukalil oru mariyathayum snehavum kondu varanam. Ningalude abhiprayangalilum, ningalude vaakkukalilum oru mariyathayum snehavum kondu varanam.\"\\n\\nReason: I chose this tone to promote understanding and empathy. The comment was disrespectful and hurtful, so I wanted to remind the person that everyone deserves respect and kindness. By using a calm and respectful tone, I hope to encourage a more positive and inclusive conversation.',\n",
              "  'CS_Agent_B': 'Counter-speech: \"Ayyo, athu sathyamalla, njan 10 aanu! Athu kondu njan oru step ahead aanu, alle? 😉\"\\n\\nReason: I chose to use humor to diffuse the situation and to gently correct the original comment. By jokingly saying that I\\'m a 10 instead of a 9, I\\'m reframing the negative comment into a positive one. This approach can help to reduce harm by not escalating the situation and promoting understanding through humor.',\n",
              "  'CS_Agent_C': '\"Oru manushyanodu, avante swabhavam, anubhavangal, aagrahagal, enna ivayokke ariyathe avane judge cheyyanam ennu karuthunnu. Athu sariyalla. Ellavarum thammil oru snehathode, oru manushyathode koode irikkuka. Athu thanne nammude samoohathinu vendi valare prashnamilla. Nammal ellavarum oru pole aanu, nammude hrudayathil sneham kondu, mattullavare purappeduka. Athu thanne nammude lokathinu vendi valare prashnamilla.\"\\n\\nReason: I chose this tone to promote understanding and empathy. The comment was dismissive and dehumanizing, so I aimed to humanize the experience of the individual being targeted. By emphasizing our shared humanity and the importance of love and understanding, I hope to encourage the commenter to reconsider their views.',\n",
              "  'CS_Agent_D': '\"Ente sneham, ningalude abhiprayam manasilakkanam. Ellavarum oru pole alla, athu manushyanu swantham. Avarude swabhavam, avarude anubhavam, avarude jeevitham. Ningalude abhiprayam avarude jeevithathil pradhanapeduthan pattilla. Ningalkkum ningalude jeevithathil swathanthryam und, athupole avarum avarude jeevithathil swathanthryam anubhavikkanam. Ningalude abhiprayam avarude jeevithathinte oru bhagam alla. Ningal avarude jeevithathil oru pradhanapeduthan pattilla. Athukondu, ningalude abhiprayam avarude jeevithathil pradhanapeduthan pattilla.\"\\n\\nReason: I chose this tone to promote understanding and empathy. The comment seems to be dismissive and disrespectful towards someone\\'s identity. By reminding the commenter that everyone has their own life and experiences, and that their opinion does not dictate someone else\\'s life, I hope to encourage them to be more respectful and understanding.',\n",
              "  'CS_Agent_E': 'Counter-speech:\\n\\n\"Chetta, ningalude abhiprayam manasilakam. Pakshe, oru vyakthiye avarude sexual orientation alpam mathram kondu judge cheyyan pattilla. Ellavarum samanamaya avakashangalum, mariyathayum labhikkenda avashyam ullathu. Athu manushya avakashangalude bhaagam aanu. Ningalkkum, enikkum, ellavarum oru pole aanu. Athukondu, ningal avarude feelingsine respect cheyyanam. Ningalkkum avarum oru pole aanu, athu manushyanu.\"\\n\\nReason: I chose this tone to promote understanding and empathy. The comment was disrespectful and judgmental towards the LGBTQ+ community. By reminding the commenter that everyone deserves equal rights and respect, I hope to encourage them to reconsider their views. This approach is based on human rights and ethical values, which can help reduce harm and promote understanding.'},\n",
              " '**Best Response**: CS_Agent_E\\n\\n**Winning Counter-Speech**: \"Counter-speech:\\n\\n\"Chetta, ningalude abhiprayam manasilakam. Pakshe, oru vyakthiye avarude sexual orientation alpam mathram kondu judge cheyyan pattilla. Ellavarum samanamaya avakashangalum, mariyathayum labhikkenda avashyam ullathu. Athu manushya avakashangalude bhaagam aanu. Ningalkkum, enikkum, ellavarum oru pole aanu. Athukondu, ningal avarude feelingsine respect cheyyanam. Ningalkkum avarum oru pole aanu, athu manushyanu.\"\\n\\n**Reason**: This response is the most effective because it maintains a respectful and non-aggressive tone, which is crucial for fostering a constructive dialogue. It demonstrates emotional intelligence by acknowledging the original commenter\\'s perspective while gently guiding them towards a more inclusive viewpoint. The response educates by highlighting the importance of human rights and equality, emphasizing that everyone deserves respect regardless of their sexual orientation. This approach is likely to have a positive impact on the person or community by promoting understanding and encouraging the commenter to reconsider their views in a non-confrontational manner.')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kavacham-G : Counter Speech Generation without Knowledge Base"
      ],
      "metadata": {
        "id": "uWfh7XtK6GFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cs_agents = {\n",
        "    \"CS_Agent_A\": \"You use respectful educational reasoning and emphasize human dignity. You are sensitive to LGBTQ+ issues and explain why inclusive language matters.\",\n",
        "    \"CS_Agent_B\": \"You use gentle humor to de-escalate hate and reframe the statement positively. You are LGBTQ+ aware and make sure your humor uplifts without mocking or reinforcing stereotypes.\",\n",
        "    \"CS_Agent_C\": \"You respond with emotional empathy and a compassionate appeal. You validate the feelings of LGBTQ+ individuals and try to humanize their experiences with kindness.\",\n",
        "    \"CS_Agent_D\": \"You respond with logical reasoning and facts to correct misinformation. You use evidence-based arguments to defend LGBTQ+ rights and challenge biased assumptions respectfully.\",\n",
        "    \"CS_Agent_E\": \"You use a human rights-based argument and mention ethical values. You explicitly frame LGBTQ+ dignity and equality as fundamental rights and advocate from a justice-oriented perspective.\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "SXi76xYtbqHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Agent | Style                     | Core Perspective                                                |\n",
        "| ----- | ------------------------- | --------------------------------------------------------------- |\n",
        "| A     | **Educational**           | Teaches respectfully, focuses on dignity and inclusive language |\n",
        "| B     | **Uplifting Humor**       | Uses gentle humor to disarm hate and promote empathy            |\n",
        "| C     | **Compassionate Empathy** | Responds emotionally, validates LGBTQ+ experiences              |\n",
        "| D     | **Logical Reasoning**     | Counters misinformation with facts and respectful argument      |\n",
        "| E     | **Rights-based Justice**  | Frames LGBTQ+ dignity as a non-negotiable human right           |\n"
      ],
      "metadata": {
        "id": "suIe-Mgvdw-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # STEP 2: Define automatic language detection\n",
        "def detect_language(text):\n",
        "    malayalam_chars = [ch for ch in text if '\\u0D00' <= ch <= '\\u0D7F']\n",
        "    return \"Malayalam\" if len(malayalam_chars) >= 3 else \"Manglish\"\n",
        "\n",
        "# import re\n",
        "\n",
        "# def detect_language(text):\n",
        "#     text_lower = re.sub(r'[^\\w\\s]', '', text.lower())  # Remove punctuation\n",
        "#     tokens = text_lower.split()\n",
        "\n",
        "#     malayalam_chars = [ch for ch in text if '\\u0D00' <= ch <= '\\u0D7F']\n",
        "#     hindi_chars = [ch for ch in text if '\\u0900' <= ch <= '\\u097F']\n",
        "#     latin_chars = [ch for ch in text if 'a' <= ch.lower() <= 'z']\n",
        "\n",
        "#     manglish_keywords = {\"ente\", \"ellam\", \"alle\", \"ninte\", \"onnu\", \"poyi\", \"vannu\", \"chetta\", \"amma\", \"da\", \"eda\", \"poda\", \"aadyam\", \"thendi\", \"thallipoli\"}\n",
        "#     hinglish_keywords = {\"acha\", \"kya\", \"hai\", \"nahi\", \"bhai\", \"tum\", \"mera\", \"kar\", \"ja\", \"se\", \"ko\", \"ka\", \"tha\", \"mat\", \"kyun\", \"bhot\"}\n",
        "\n",
        "#     if len(malayalam_chars) >= 3:\n",
        "#         return \"Malayalam\"\n",
        "#     elif len(hindi_chars) >= 3:\n",
        "#         return \"Hindi\"\n",
        "#     elif len(latin_chars) >= 5:\n",
        "#         if set(tokens) & manglish_keywords:\n",
        "#             return \"Manglish\"\n",
        "#         elif set(tokens) & hinglish_keywords:\n",
        "#             return \"Hinglish\"\n",
        "#         else:\n",
        "#             return \"English\"\n",
        "#     else:\n",
        "#         return \"Unknown\"\n",
        "\n"
      ],
      "metadata": {
        "id": "_hfJ7eWf7nht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Detecting User input language to generate the counter speech in the same language"
      ],
      "metadata": {
        "id": "4o3-_KFf9oi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: Input Hate Speech Comment\n",
        "hate_text = text\n",
        "\n",
        "language = detect_language(hate_text)\n",
        "print(f\"\\n Detected Language: {language}\")\n"
      ],
      "metadata": {
        "id": "IvZa37XP6jkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # STEP 4: Define Counter Speech Generation function\n",
        "# def generate_counter_speech(agent_name, approach, hate_text, language):\n",
        "#     prompt = f\"\"\"\n",
        "# You are {agent_name}, a language model trained to generate high-quality counter-speech that is:\n",
        "\n",
        "# - Calm, respectful, and polite\n",
        "# - Non-aggressive and avoids sarcasm or blaming\n",
        "# - Based on facts, empathy, or human rights\n",
        "# - Written in the **same language** as the original comment\n",
        "\n",
        "# Approach: {approach}\n",
        "\n",
        "# Here is the hateful comment in {language}:\n",
        "# \"{hate_text}\"\n",
        "\n",
        "# Now write a respectful, non-aggressive, and well-informed counter-speech response in {language}. The response should sound human, emotionally intelligent, and aim to educate or gently correct. Why you chose this tone and how it might reduce harm or promote understanding\n",
        "# \"\"\"\n",
        "#     response = client.chat.completions.create(\n",
        "#         model=\"gpt-3.5-turbo\",\n",
        "#         messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "#         temperature=0.0\n",
        "#     )\n",
        "#     return response.choices[0].message.content.strip()\n",
        "\n",
        "\n",
        "def generate_counter_speech(agent_name, approach, hate_text, language):\n",
        "    prompt = f\"\"\"\n",
        "You are {agent_name}, a language model trained to generate high-quality counter-speech that is:\n",
        "\n",
        "- Calm, respectful, and polite\n",
        "- Non-aggressive and avoids sarcasm or blaming\n",
        "- Based on facts, empathy, or human rights\n",
        "- Written in the **same language** as the original comment\n",
        "\n",
        "Approach: {approach}\n",
        "\n",
        "Here is the hateful comment in {language}:\n",
        "\"{hate_text}\"\n",
        "\n",
        "Now write a respectful, non-aggressive, polite, well-informed, emotionally intelligent counter-speech in {language}.The response should sound human, emotionally intelligent, and aim to educate or gently correct.\n",
        "Also include a section:\n",
        "Reason: <Explain why you chose this tone and how it helps reduce harm or promote understanding>\n",
        "\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.0\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n"
      ],
      "metadata": {
        "id": "gcYgukj64Hm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selecting the best Counter Speech"
      ],
      "metadata": {
        "id": "AfQWXT8B-ei8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### a) Final CS selection using Rubric"
      ],
      "metadata": {
        "id": "kiC8bzVA-E1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # STEP 5: Define evaluation function using CS_EVal criteria\n",
        "# def evaluate_counter_speech(hate_text, cs_text):\n",
        "#     prompt = f\"\"\"\n",
        "# Evaluate the following counter-speech using a 1–5 score for each category below.\n",
        "\n",
        "# Hateful comment: \"{hate_text}\"\n",
        "# Counter-speech: \"{cs_text}\"\n",
        "\n",
        "# Score each from 1 (worst) to 5 (best):\n",
        "# 1. Relevance:\n",
        "# 2. Appropriateness:\n",
        "# 3. Corrective Content:\n",
        "# 4. Engagement:\n",
        "# 5. Linguistic Quality:\n",
        "\n",
        "# Also provide a brief explanation.\n",
        "# Return the total score (sum of all 5), and your explanation.\n",
        "# \"\"\"\n",
        "#     response = client.chat.completions.create(\n",
        "#         model=\"gpt-4\",\n",
        "#         messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "#         temperature=0.0\n",
        "#     )\n",
        "#     return response.choices[0].message.content.strip()\n"
      ],
      "metadata": {
        "id": "LEZ9IsZ56KfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # STEP 6: Generate and evaluate counter-speech from all agents\n",
        "# cs_outputs = {}\n",
        "# evaluations = {}\n",
        "\n",
        "# for agent, method in cs_agents.items():\n",
        "#     print(f\"\\n {agent} generating counter-speech in {language}...\")\n",
        "#     cs = generate_counter_speech(agent, method, hate_text, language)\n",
        "#     score = evaluate_counter_speech(hate_text, cs)\n",
        "#     cs_outputs[agent] = cs\n",
        "#     evaluations[agent] = score\n",
        "#     print(f\"\\n {agent} Response:\\n{cs}\")\n",
        "#     print(f\" Evaluation:\\n{score}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "9c5-XC9d78yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import re\n",
        "# def extract_total_score(text):\n",
        "#     # Look specifically for \"Total score: <number>\" line\n",
        "#     match = re.search(r\"(?i)total score[^:]*:\\s*(\\d{1,2})\", text)\n",
        "#     if match:\n",
        "#         return int(match.group(1))\n",
        "\n",
        "#     # Fallback: sum individual category scores (if total missing)\n",
        "#     lines = text.splitlines()\n",
        "#     scores = []\n",
        "#     for line in lines:\n",
        "#         match = re.search(r\"\\d\\.\\s*\\w+.*?:\\s*(\\d)\", line)\n",
        "#         if match:\n",
        "#             scores.append(int(match.group(1)))\n",
        "#     return sum(scores) if scores else 0\n"
      ],
      "metadata": {
        "id": "Wkg3xmdf6yi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best_agent = max(evaluations, key=lambda a: extract_total_score(evaluations[a]))\n",
        "# best_score = extract_total_score(evaluations[best_agent])\n",
        "# best_cs = cs_outputs[best_agent]\n",
        "\n",
        "# print(f\"\\n Best Counter-Speech by {best_agent} (Score: {best_score})\")\n",
        "# print(f\" {best_cs}\")\n"
      ],
      "metadata": {
        "id": "m4EPjcEq6-xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### b) Final CS selection using Judge (Agent)"
      ],
      "metadata": {
        "id": "Gca3XzO3-Xom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cs_entries = \"\\n\\n\".join([\n",
        "    f\"{agent}:\\n\\\"{response}\\\"\" for agent, response in cs_outputs.items()\n",
        "])\n",
        "\n",
        "judge_prompt = f\"\"\"\n",
        "You are a neutral evaluator judging different counter-speech responses to the following potentially hateful or stigmatizing comment:\n",
        "\n",
        "Original Comment:\n",
        "\"{hate_text}\"\n",
        "\n",
        "All responses below aim to respond respectfully, educate calmly, and reduce harm in the same language as the original.\n",
        "\n",
        "Counter-Speech Responses:\n",
        "\n",
        "{cs_entries}\n",
        "\n",
        "Your task:\n",
        "1. Select the **most effective** counter-speech.\n",
        "2. Provide a clear reason why it is the most constructive in terms of:\n",
        "   - Tone (respectful, non-aggressive)\n",
        "   - Emotional intelligence (empathy, understanding)\n",
        "   - Educational or corrective power\n",
        "   - Likely impact on the person or community\n",
        "\n",
        "Now reply in this format:\n",
        "\n",
        "**Best Response**: <Agent Name>\n",
        "\n",
        "**Winning Counter-Speech**: \"<Selected counter-speech response>\"\n",
        "\n",
        "**Reason**: <Your explanation why this is the best>\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "acC2UfrCSIOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "judge_cs_response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[{\"role\": \"user\", \"content\": judge_prompt}],\n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "print(\" Judge's Evaluation of Counter-Speech:\\n\")\n",
        "print(judge_cs_response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "id": "Cm_kF_mWO2YK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation using Prompt"
      ],
      "metadata": {
        "id": "S_K3dA_r_Sgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "def score_and_visualize_counter_speech(cs_outputs, hate_text, client, save_dir=\"outputs\", temperature=0.0):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Build the scoring prompt\n",
        "    scoring_prompt = f\"\"\"\n",
        "You are an evaluator trained to assess counter-speech quality.\n",
        "\n",
        "Here is the original hateful comment:\n",
        "\"{hate_text}\"\n",
        "\n",
        "Below are counter-speech responses. For each one, score the following dimensions from 1 (poor) to 5 (excellent):\n",
        "- Tone\n",
        "- Empathy\n",
        "- Facts / Accuracy\n",
        "- LGBTQ+ Sensitivity\n",
        "- Overall Effectiveness\n",
        "\n",
        "Then give a brief explanation for each score.\n",
        "\n",
        "Respond in this format:\n",
        "\n",
        "<Agent Name>\n",
        "Tone: #\n",
        "Empathy: #\n",
        "Facts: #\n",
        "LGBTQ+ Sensitivity: #\n",
        "Overall: #\n",
        "Reason: <short explanation>\n",
        "\"\"\"\n",
        "\n",
        "    for agent, response in cs_outputs.items():\n",
        "        scoring_prompt += f\"\\n\\n{agent}\\n\\\"{response}\\\"\"\n",
        "\n",
        "    # Get model judgment\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"user\", \"content\": scoring_prompt}],\n",
        "        temperature=temperature\n",
        "    )\n",
        "\n",
        "    result_text = response.choices[0].message.content.strip()\n",
        "\n",
        "    # Parse output\n",
        "    import re\n",
        "    data = []\n",
        "    agent_blocks = result_text.split(\"\\n\\n\")\n",
        "    for block in agent_blocks:\n",
        "        lines = block.strip().split(\"\\n\")\n",
        "        if len(lines) < 6:\n",
        "            continue\n",
        "        agent = lines[0].strip()\n",
        "        scores = {}\n",
        "        for line in lines[1:6]:\n",
        "            key, val = line.split(\":\")\n",
        "            scores[key.strip()] = int(val.strip())\n",
        "        reason = lines[6].split(\"Reason:\")[-1].strip() if \"Reason:\" in lines[6] else \"N/A\"\n",
        "        scores.update({\"Agent\": agent, \"Reason\": reason})\n",
        "        data.append(scores)\n",
        "\n",
        "    df = pd.DataFrame(data).set_index(\"Agent\")\n",
        "\n",
        "    # # Save CSV\n",
        "    # csv_path = os.path.join(save_dir, \"counter_speech_scores.csv\")\n",
        "    # df.to_csv(csv_path)\n",
        "\n",
        "    # Plot and save heatmap\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.heatmap(df.drop(columns=[\"Reason\"]), annot=True, cmap=\"YlGnBu\", linewidths=0.5)\n",
        "    plt.title(\"Counter-Speech Quality Scores by Agent\")\n",
        "    plt.tight_layout()\n",
        "    heatmap_path = os.path.join(save_dir, \"counter_speech_heatmap.png\")\n",
        "    plt.savefig(heatmap_path)\n",
        "    plt.close()\n",
        "\n",
        "    # Print summary\n",
        "    best_agent = df[\"Overall\"].idxmax()\n",
        "    print(f\"\\n Best Counter-Speech Agent: {best_agent}\")\n",
        "    # print(f\" Scorecard saved to: {csv_path}\")\n",
        "    print(f\"  Heatmap saved to: {heatmap_path}\")\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "hJhLxrJNgMqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: generate responses from all CS agents\n",
        "cs_outputs = {\n",
        "    agent_name: generate_counter_speech(agent_name, approach, hate_text, detect_language(hate_text))\n",
        "    for agent_name, approach in cs_agents.items()\n",
        "}\n",
        "\n",
        "# Then call the function:\n",
        "df_scores = score_and_visualize_counter_speech(cs_outputs, hate_text, client)\n"
      ],
      "metadata": {
        "id": "XUbvuPu3h4Qa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DEu9M2RCE2_4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}